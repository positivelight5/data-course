{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E42MLrKUCo8U"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05MOc1D-Co8j"
   },
   "source": [
    "# Завдання 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGZGcmHDCo8p"
   },
   "source": [
    "Для кожної із адміністративних одиниць України завантажити тестові структуровані файли, що містять значення VHI-індексу.\n",
    "Ця процедура має бути автоматизована, параметром процедури має бути індекс (номер) області.\n",
    "При зберіганні файлу до його імені потрібно додати дату та час завантаження.\n",
    "\n",
    "Передбачити повторні запуски скрипту, довантаження нових даних та колізію\n",
    "даних;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CT3VajTFCo8r",
    "outputId": "5b869cc2-e6a9-45de-e684-d588bc916658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл для області 1 успішно завантажено: CSV_Files\\VHI_1_20250328_160402.csv\n",
      "Файл для області 2 успішно завантажено: CSV_Files\\VHI_2_20250328_160405.csv\n",
      "Файл для області 3 успішно завантажено: CSV_Files\\VHI_3_20250328_160407.csv\n",
      "Файл для області 4 успішно завантажено: CSV_Files\\VHI_4_20250328_160408.csv\n",
      "Файл для області 5 успішно завантажено: CSV_Files\\VHI_5_20250328_160411.csv\n",
      "Файл для області 6 успішно завантажено: CSV_Files\\VHI_6_20250328_160414.csv\n",
      "Файл для області 7 успішно завантажено: CSV_Files\\VHI_7_20250328_160416.csv\n",
      "Файл для області 8 успішно завантажено: CSV_Files\\VHI_8_20250328_160418.csv\n",
      "Файл для області 9 успішно завантажено: CSV_Files\\VHI_9_20250328_160419.csv\n",
      "Файл для області 10 успішно завантажено: CSV_Files\\VHI_10_20250328_160422.csv\n",
      "Файл для області 11 успішно завантажено: CSV_Files\\VHI_11_20250328_160423.csv\n",
      "Файл для області 12 успішно завантажено: CSV_Files\\VHI_12_20250328_160426.csv\n",
      "Файл для області 13 успішно завантажено: CSV_Files\\VHI_13_20250328_160427.csv\n",
      "Файл для області 14 успішно завантажено: CSV_Files\\VHI_14_20250328_160431.csv\n",
      "Файл для області 15 успішно завантажено: CSV_Files\\VHI_15_20250328_160432.csv\n",
      "Файл для області 16 успішно завантажено: CSV_Files\\VHI_16_20250328_160436.csv\n",
      "Файл для області 17 успішно завантажено: CSV_Files\\VHI_17_20250328_160438.csv\n",
      "Файл для області 18 успішно завантажено: CSV_Files\\VHI_18_20250328_160440.csv\n",
      "Файл для області 19 успішно завантажено: CSV_Files\\VHI_19_20250328_160443.csv\n",
      "Файл для області 20 успішно завантажено: CSV_Files\\VHI_20_20250328_160445.csv\n",
      "Файл для області 21 успішно завантажено: CSV_Files\\VHI_21_20250328_160446.csv\n",
      "Файл для області 22 успішно завантажено: CSV_Files\\VHI_22_20250328_160449.csv\n",
      "Файл для області 23 успішно завантажено: CSV_Files\\VHI_23_20250328_160450.csv\n",
      "Файл для області 24 успішно завантажено: CSV_Files\\VHI_24_20250328_160453.csv\n",
      "Файл для області 25 успішно завантажено: CSV_Files\\VHI_25_20250328_160456.csv\n",
      "Файл для області 26 успішно завантажено: CSV_Files\\VHI_26_20250328_160457.csv\n",
      "Файл для області 27 успішно завантажено: CSV_Files\\VHI_27_20250328_160459.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import hashlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Папка для збереження CSV-файлів\n",
    "DATA_DIR = \"CSV_Files\"\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "# Функція для обчислення хешу файлу (SHA-256)\n",
    "def compute_sha256(file_path):\n",
    "    \"\"\"Обчислює SHA-256 хеш файлу для перевірки дублікатів.\"\"\"\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256.update(chunk)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "# Функція для перевірки коректності відповіді сервера\n",
    "def is_valid_response(response):\n",
    "    \"\"\"Перевіряє, чи отримані коректні дані (не HTML-сторінка з помилкою).\"\"\"\n",
    "    content_type = response.getheader('Content-Type', '')\n",
    "    return 'text/plain' in content_type or 'csv' in content_type\n",
    "\n",
    "# Функція для завантаження VHI-даних для конкретної області\n",
    "def download_vhi_data(region_ID):\n",
    "    \"\"\"Завантажує VHI-дані для області та зберігає у файлі з унікальним ім'ям.\"\"\"\n",
    "\n",
    "    # Формування URL для отримання даних\n",
    "    url = f\"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={region_ID}&year1=1981&year2=2024&type=Mean\"\n",
    "\n",
    "    # Генерація унікальної назви файлу із зазначенням часу\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file_path = os.path.join(DATA_DIR, f\"VHI_{region_ID}_{timestamp}.csv\")\n",
    "\n",
    "    try:\n",
    "        # Відправка запиту та отримання даних\n",
    "        response = urllib.request.urlopen(url)\n",
    "\n",
    "        content = response.read()\n",
    "\n",
    "        # Запис отриманих даних у CSV-файл\n",
    "        with open(output_file_path, 'wb') as file:\n",
    "            file.write(content)\n",
    "\n",
    "        # Перевірка наявності дубліката\n",
    "        for stored_file in os.listdir(DATA_DIR):\n",
    "            if stored_file.endswith(\".csv\") and f\"Region{region_ID}\" in stored_file:\n",
    "                stored_path = os.path.join(DATA_DIR, stored_file)\n",
    "\n",
    "                # Якщо файл ідентичний, видаляємо новий дублікат\n",
    "                if stored_path != output_file_path and os.path.exists(stored_path):\n",
    "                    if compute_sha256(stored_path) == compute_sha256(output_file_path):\n",
    "                        print(f\"Файл для області {region_ID} вже є. Видаляю дубль.\")\n",
    "                        os.remove(output_file_path)\n",
    "                        return\n",
    "\n",
    "        print(f\"Файл для області {region_ID} успішно завантажено: {output_file_path}\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Помилка при отриманні даних для області {region_ID}: {err}\")\n",
    "\n",
    "# Завантаження даних для всіх 27 адміністративних одиниць України (25 областей + АР Крим + Київ)\n",
    "for region_ID in range(1, 28):\n",
    "    download_vhi_data(region_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmfDGT-7Co8t"
   },
   "source": [
    "# Завдання 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFWlKMxgCo8u"
   },
   "source": [
    "Зчитати завантажені текстові файли у фрейм\n",
    "(https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) (детальніше\n",
    "про роботу із фреймами буде розказано у подальших лабораторних роботах).\n",
    "Імена стовбців фрейму мають бути змістовними та легкими для сприйняття (не\n",
    "повинно бути спеціалізованих символів, пробілів тощо). Ця задача має бути\n",
    "реалізована у вигляді окремої процедури, яка на вхід приймає шлях до\n",
    "директорії, в якій зберігаються файли;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZoZCneAGCo8v",
    "outputId": "87de37b7-87ed-454a-c6be-5dba1ba30d18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5760\\1226661203.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_data = pd.concat([combined_data, df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Об'єднані дані успішно збережено у full.csv\n",
      "Перші 10 рядків:\n",
      "   Year Week    SMN     SMT    VCI    TCI    VHI PROVINCE_ID\n",
      "0  1982    1  0.053  260.31  45.01  39.46  42.23           1\n",
      "1  1982    2  0.054  262.29  46.83  31.75  39.29           1\n",
      "2  1982    3  0.055  263.82  48.13  27.24  37.68           1\n",
      "3  1982    4  0.053  265.33  46.09  23.91  35.00           1\n",
      "4  1982    5  0.050  265.66  41.46  26.65  34.06           1\n",
      "5  1982    6  0.048  266.55  36.56  29.46  33.01           1\n",
      "6  1982    7  0.048  267.84  32.17  31.14  31.65           1\n",
      "7  1982    8  0.050  269.30  30.30  32.50  31.40           1\n",
      "8  1982    9  0.052  270.75  28.23  35.22  31.73           1\n",
      "9  1982   10  0.056  272.73  25.25  37.63  31.44           1\n",
      "Ось останні 10 рядків:\n",
      "       Year Week    SMN     SMT    VCI    TCI    VHI PROVINCE_ID\n",
      "59012  2024   43  0.259  281.45  79.71  17.45  48.58          27\n",
      "59013  2024   44  0.229  279.41  76.74  13.33  45.04          27\n",
      "59014  2024   45  0.206  278.07  77.64   8.70  43.17          27\n",
      "59015  2024   46  0.177  275.95  74.84  10.23  42.53          27\n",
      "59016  2024   47  0.149  273.20  71.22  16.89  44.05          27\n",
      "59017  2024   48  0.128  270.55  64.97  25.53  45.25          27\n",
      "59018  2024   49  0.115  269.06  60.12  27.24  43.68          27\n",
      "59019  2024   50  0.104  267.75  55.24  25.89  40.57          27\n",
      "59020  2024   51  0.094  266.45  51.16  24.29  37.72          27\n",
      "59021  2024   52  0.093  266.38  54.22  21.11  37.66          27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Папка з CSV-файлами та вихідний файл\n",
    "DATA_DIR = \"CSV_Files\"  # Твоя директорія\n",
    "output_path = \"full.csv\" # Файл для збереження\n",
    "\n",
    "# Імена колонок для зчитування\n",
    "COLUMN_NAMES = [\"Year\", \"Week\", \"SMN\", \"SMT\", \"VCI\", \"TCI\", \"VHI\", \"PROVINCE_ID\"]\n",
    "\n",
    "# Порожній DataFrame для об'єднання даних\n",
    "combined_data = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "# Отримуємо список CSV-файлів, відсортованих за номером області\n",
    "files = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.csv')],\n",
    "               key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "\n",
    "# Обробка кожного файлу\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(DATA_DIR, file_name)\n",
    "\n",
    "    try:\n",
    "        # Отримуємо ID області з назви файлу\n",
    "        province_id = int(re.findall(r'\\d+', file_name)[0])\n",
    "\n",
    "        # Зчитуємо файл, пропускаючи перші 2 рядки\n",
    "        df = pd.read_csv(file_path, skiprows=2, names=COLUMN_NAMES)\n",
    "\n",
    "        # Видаляємо HTML-теги з Year\n",
    "        df[\"Year\"] = df[\"Year\"].astype(str).str.replace(r'<tt><pre>|</pre></tt>', '', regex=True)\n",
    "\n",
    "        # pd.to_numeric(..., errors='coerce') замінює некоректні значення на NaN, якщо такі є.\n",
    "        df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors='coerce')\n",
    "        df[\"Week\"] = pd.to_numeric(df[\"Week\"], errors='coerce')\n",
    "\n",
    "        # Видаляє рядки з NaN у Year та Week, щоб уникнути помилок при подальших обчисленнях\n",
    "        df.dropna(subset=[\"Year\", \"Week\"], inplace=True)\n",
    "\n",
    "        # Перетворює Year і Week на цілі числа (int):\n",
    "        df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "        df[\"Week\"] = df[\"Week\"].astype(int)\n",
    "\n",
    "        # Додаємо ID області у колонку \"PROVINCE_ID\"\n",
    "        df[\"PROVINCE_ID\"] = province_id\n",
    "\n",
    "        # Видаляємо рядки з некоректними VHI та NaN\n",
    "        df = df[df[\"VHI\"] != -1].dropna()\n",
    "\n",
    "        # Додаємо оброблені дані в загальний DataFrame\n",
    "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Помилка при читанні файлу {file_name}: {e}\")\n",
    "\n",
    "# Зберігаємо результат у файл\n",
    "combined_data.to_csv(output_path, index=False)\n",
    "\n",
    "# Виводимо перші 10 рядків\n",
    "print(\"Об'єднані дані успішно збережено у\", output_path)\n",
    "print(\"Перші 10 рядків:\")\n",
    "print(combined_data.head(10))\n",
    "print(\"Ось останні 10 рядків:\")\n",
    "print(combined_data.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U24vtKtsCo8x"
   },
   "source": [
    "# Завдання 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WcY9olcCo8x"
   },
   "source": [
    "Реалізувати окрему процедуру, яка змінить індекси областей, які використані на\n",
    "порталі NOAA (за англійською абеткою) на наступні, за українською (виключно\n",
    "старі індекси на нові):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kbJLZJlACo8y",
    "outputId": "d2266ce3-19e4-430f-f09c-6c1b76a858e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оновлений файл збережено: Updated_Provinces.csv\n",
      "   Year Week    SMN     SMT    VCI    TCI    VHI  PROVINCE_ID\n",
      "0  1982    1  0.053  260.31  45.01  39.46  42.23           24\n",
      "1  1982    2  0.054  262.29  46.83  31.75  39.29           24\n",
      "2  1982    3  0.055  263.82  48.13  27.24  37.68           24\n",
      "3  1982    4  0.053  265.33  46.09  23.91  35.00           24\n",
      "4  1982    5  0.050  265.66  41.46  26.65  34.06           24\n",
      "5  1982    6  0.048  266.55  36.56  29.46  33.01           24\n",
      "6  1982    7  0.048  267.84  32.17  31.14  31.65           24\n",
      "7  1982    8  0.050  269.30  30.30  32.50  31.40           24\n",
      "8  1982    9  0.052  270.75  28.23  35.22  31.73           24\n",
      "9  1982   10  0.056  272.73  25.25  37.63  31.44           24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_province_ids(df):\n",
    "\n",
    "    province_mapping = {\n",
    "        1: 24,  2: 26,  3: 25,  4: 27,  5: 3,   6: 4,   7: 8,\n",
    "        8: 21,  9: 22, 10: 23, 11: 10, 12: 9,  13: 11, 14: 12,\n",
    "       15: 13, 16: 14, 17: 15, 18: 16, 19: 17, 20: 18, 21: 19,\n",
    "       22: 20, 23: 6,  24: 1,  25: 2,  26: 7,  27: 5\n",
    "    }\n",
    "\n",
    "    # Переконуємося, що колонка \"PROVINCE_ID\" є у DataFrame\n",
    "    if \"PROVINCE_ID\" not in df.columns:\n",
    "        print(\"Колонка 'PROVINCE_ID' не знайдена у DataFrame!\")\n",
    "        return df\n",
    "\n",
    "    # Оновлення значень\n",
    "    df[\"PROVINCE_ID\"] = df[\"PROVINCE_ID\"].map(province_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Оновлення індексів у `combined_data`\n",
    "combined_data = update_province_ids(combined_data)\n",
    "\n",
    "# Збереження у файл\n",
    "output_file = \"Updated_Provinces.csv\"\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Вивід результату\n",
    "print(f\"Оновлений файл збережено: {output_file}\")\n",
    "print(combined_data.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRKjkYZaCo8z"
   },
   "source": [
    "# Завдання 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUwiy_jkCo8z"
   },
   "source": [
    "### Реалізувати процедури для формування вибірок наступного виду (включаючи елементи аналізу):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7v84qjObCo80"
   },
   "source": [
    "o Ряд VHI для області за вказаний рік;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZYH_C95Co80"
   },
   "source": [
    "1. Отримати ряд VHI для області за вказаний рік"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "i19ac7C6Co83",
    "outputId": "b1347f6d-7c2b-400e-872e-6d5519854197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year Week    VHI\n",
      "23786  2020    1  37.78\n",
      "23787  2020    2  38.41\n",
      "23788  2020    3  39.74\n",
      "23789  2020    4  41.90\n",
      "23790  2020    5  43.53\n",
      "23791  2020    6  43.37\n",
      "23792  2020    7  41.50\n",
      "23793  2020    8  39.53\n",
      "23794  2020    9  38.90\n",
      "23795  2020   10  39.07\n",
      "23796  2020   11  38.66\n",
      "23797  2020   12  38.60\n",
      "23798  2020   13  37.73\n",
      "23799  2020   14  35.97\n",
      "23800  2020   15  34.35\n",
      "23801  2020   16  33.99\n",
      "23802  2020   17  35.73\n",
      "23803  2020   18  38.44\n",
      "23804  2020   19  42.71\n",
      "23805  2020   20  47.25\n",
      "23806  2020   21  48.13\n",
      "23807  2020   22  47.18\n",
      "23808  2020   23  45.82\n",
      "23809  2020   24  46.15\n",
      "23810  2020   25  48.05\n",
      "23811  2020   26  49.25\n",
      "23812  2020   27  51.20\n",
      "23813  2020   28  53.44\n",
      "23814  2020   29  55.37\n",
      "23815  2020   30  56.30\n",
      "23816  2020   31  54.89\n",
      "23817  2020   32  52.78\n",
      "23818  2020   33  48.81\n",
      "23819  2020   34  45.37\n",
      "23820  2020   35  43.23\n",
      "23821  2020   36  41.38\n",
      "23822  2020   37  40.84\n",
      "23823  2020   38  39.22\n",
      "23824  2020   39  37.70\n",
      "23825  2020   40  37.41\n",
      "23826  2020   41  36.16\n",
      "23827  2020   42  32.79\n",
      "23828  2020   43  30.85\n",
      "23829  2020   44  29.27\n",
      "23830  2020   45  30.15\n",
      "23831  2020   46  32.31\n",
      "23832  2020   47  35.10\n",
      "23833  2020   48  37.69\n",
      "23834  2020   49  38.98\n",
      "23835  2020   50  40.16\n",
      "23836  2020   51  38.82\n",
      "23837  2020   52  38.73\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_for_region_year(df, province_id, year):\n",
    "\n",
    "    return df[(df[\"PROVINCE_ID\"] == province_id) & (df[\"Year\"] == year)][[\"Year\", \"Week\", \"VHI\"]]\n",
    "\n",
    "vhi_data = get_vhi_for_region_year(combined_data, province_id=10, year=2020)\n",
    "print(vhi_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MT6VbILfFs3V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year Week    VHI\n",
      "23800  2020   15  34.35\n",
      "23801  2020   16  33.99\n",
      "23802  2020   17  35.73\n",
      "23803  2020   18  38.44\n",
      "23804  2020   19  42.71\n",
      "23805  2020   20  47.25\n"
     ]
    }
   ],
   "source": [
    "# Функція для отримання індексу VHI (Vegetation Health Index) для певного регіону та року у заданому діапазоні тижнів\n",
    "def get_vhi_for_region_year(df, province_id, year, start_week, end_week):\n",
    "    # Фільтруємо DataFrame за заданими параметрами: область (PROVINCE_ID), рік (Year) і діапазон тижнів (Week)\n",
    "    return df[\n",
    "        (df[\"PROVINCE_ID\"] == province_id) &  # Вибираємо рядки з потрібним ID області\n",
    "        (df[\"Year\"] == year) &  # Вибираємо рядки з потрібним роком\n",
    "        (df[\"Week\"] >= start_week) &  # Вибираємо тижні, що знаходяться у вказаному діапазоні\n",
    "        (df[\"Week\"] <= end_week)  # Включаємо верхню межу діапазону тижнів\n",
    "    ][[\"Year\", \"Week\", \"VHI\"]]  # Вибираємо тільки необхідні колонки для виводу\n",
    "\n",
    "# Виклик функції для отримання VHI для області з ID=10 за 2020 рік у період з 15 по 20 тиждень\n",
    "vhi_data = get_vhi_for_region_year(combined_data, province_id=10, year=2020, start_week=15, end_week=20)\n",
    "\n",
    "# Виводимо результат\n",
    "print(vhi_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6zhxxA3Co84"
   },
   "source": [
    "2. Пошук екстремумів (min, max), середнього, медіани"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8NiTKoT3Co84",
    "outputId": "026bef56-70bf-4da8-d404-44ec0ad1087b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PROVINCE_ID  Year    min    max       mean  median\n",
      "0            5  2000  27.46  66.30  47.882885  47.375\n",
      "1            5  2020  35.05  58.33  44.544231  43.660\n",
      "2           10  2000  10.60  61.87  39.758269  35.915\n",
      "3           10  2020  29.27  56.30  41.359423  39.375\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_statistics(df, province_ids, years):\n",
    "\n",
    "    # Фільтруємо дані за обраними областями та роками\n",
    "    filtered_df = df[(df[\"PROVINCE_ID\"].isin(province_ids)) & (df[\"Year\"].isin(years))]\n",
    "\n",
    "    # Групуємо за областю та роком, обчислюємо статистичні показники\n",
    "    return filtered_df.groupby([\"PROVINCE_ID\", \"Year\"])[\"VHI\"].agg([\"min\", \"max\", \"mean\", \"median\"]).reset_index()\n",
    "\n",
    "# Виклик функції для областей з ID 5 і 10 у 2000 та 2020 роках\n",
    "stats = get_vhi_statistics(combined_data, province_ids=[5, 10], years=[2000, 2020])\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPAzW941Co85"
   },
   "source": [
    "3. Отримати ряд VHI за вказаний діапазон років для вказаних областей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uI7EnpZqCo85",
    "outputId": "97b3ad2d-9d3b-476e-8d72-7f0a5de59e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year Week  PROVINCE_ID    VHI\n",
      "10150  2010    1            3  52.08\n",
      "10151  2010    2            3  49.75\n",
      "10152  2010    3            3  48.82\n",
      "10153  2010    4            3  48.13\n",
      "10154  2010    5            3  46.79\n",
      "...     ...  ...          ...    ...\n",
      "56623  2020   48            7  44.96\n",
      "56624  2020   49            7  45.42\n",
      "56625  2020   50            7  46.26\n",
      "56626  2020   51            7  47.35\n",
      "56627  2020   52            7  49.46\n",
      "\n",
      "[1716 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_by_year_range(df, province_ids, start_year, end_year):\n",
    "\n",
    "    result = df[(df[\"PROVINCE_ID\"].isin(province_ids)) & (df[\"Year\"].between(start_year, end_year))]\n",
    "\n",
    "    if result.empty:\n",
    "        print(\"Дані для вказаного діапазону відсутні!\")\n",
    "\n",
    "    return result[[\"Year\", \"Week\", \"PROVINCE_ID\", \"VHI\"]]\n",
    "\n",
    "# Використання:\n",
    "province_ids = [3, 7, 12]  # Введи потрібні області\n",
    "start_year = 2010  # Початковий рік\n",
    "end_year = 2020  # Кінцевий рік\n",
    "vhi_range_data = get_vhi_by_year_range(combined_data, province_ids, start_year, end_year)\n",
    "print(vhi_range_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Dw8htnBCo86"
   },
   "source": [
    "o Для всього набору даних виявити роки, протягом яких екстремальні\n",
    "посухи торкнулися більше вказаного відсотка областей по Україні (20%\n",
    "областей - 5 областей з 25). Повернути роки, назви областей з\n",
    "екстремальними посухами та значення VHI;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaOXXn4eCo86"
   },
   "source": [
    "4. Виявити роки, коли посуха торкнулася >20% областей (VHI < 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "W97-2IpbCo87",
    "outputId": "8373ba73-8a99-4943-e33d-3e6438dfe061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  PROVINCE_ID    VHI\n",
      "949    2000           24  14.64\n",
      "950    2000           24  11.82\n",
      "951    2000           24  10.81\n",
      "952    2000           24  10.68\n",
      "953    2000           24  12.30\n",
      "...     ...          ...    ...\n",
      "55932  2007            7  11.55\n",
      "55933  2007            7  10.88\n",
      "55934  2007            7  11.06\n",
      "55935  2007            7  12.05\n",
      "55936  2007            7  13.84\n",
      "\n",
      "[88 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def find_drought_years(df, threshold=15, affected_percentage=0.2):\n",
    "\n",
    "    province_count = df[\"PROVINCE_ID\"].nunique()  # Загальна кількість областей\n",
    "    min_affected = int(province_count * affected_percentage)  # Мінімальна кількість уражених областей\n",
    "\n",
    "    drought_data = df[df[\"VHI\"] < threshold].groupby([\"Year\"])[\"PROVINCE_ID\"].nunique().reset_index()\n",
    "    drought_years = drought_data[drought_data[\"PROVINCE_ID\"] >= min_affected]\n",
    "\n",
    "    if drought_years.empty:\n",
    "        print(\"Не знайдено років, коли посуха торкнулася 20% областей.\")\n",
    "        return None\n",
    "\n",
    "    # Отримуємо детальні дані про області, які потрапили під посуху\n",
    "    drought_details = df[(df[\"Year\"].isin(drought_years[\"Year\"])) & (df[\"VHI\"] < threshold)]\n",
    "\n",
    "    return drought_details[[\"Year\", \"PROVINCE_ID\", \"VHI\"]]\n",
    "\n",
    "# Використання:\n",
    "drought_info = find_drought_years(combined_data)\n",
    "print(drought_info)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
